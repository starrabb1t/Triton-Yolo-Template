name: triton-server

services:
  yolo-trt-gpu:
    image: nvcr.io/nvidia/tritonserver:24.09-py3
    volumes:
      - ./models:/models
    ports:
      - 8001:8001
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
    command: tritonserver --model-repository=/models
    restart: unless-stopped